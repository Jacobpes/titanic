{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# NumPy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Dataframe operations\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# NumPy\n",
    "import numpy as np # type: ignore\n",
    "\n",
    "# Dataframe operations\n",
    "import pandas as pd # type: ignore\n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import MinMaxScaler # type: ignore\n",
    "from sklearn.preprocessing import StandardScaler # type: ignore\n",
    "from sklearn.utils import shuffle # type: ignore\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression # type: ignore\n",
    "from sklearn.linear_model import Perceptron # type: ignore\n",
    "from sklearn import svm #support vector Machine # type: ignore\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest # type: ignore\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN # type: ignore\n",
    "from sklearn.naive_bayes import GaussianNB #Naive bayes # type: ignore\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree # type: ignore\n",
    "from sklearn.model_selection import train_test_split #training and testing data split# type: ignore\n",
    "from sklearn import metrics #accuracy measure # type: ignore\n",
    "from sklearn.metrics import confusion_matrix #for confusion matrix # type: ignore\n",
    "from sklearn.ensemble import VotingClassifier # type: ignore\n",
    "from sklearn.ensemble import AdaBoostClassifier # type: ignore\n",
    "from sklearn.neural_network import MLPClassifier # type: ignore\n",
    "\n",
    "# Cross-validation\n",
    "from sklearn.model_selection import KFold #for K-fold cross validation # type: ignore\n",
    "from sklearn.model_selection import cross_val_score #score evaluation # type: ignore\n",
    "from sklearn.model_selection import cross_val_predict #prediction # type: ignore\n",
    "from sklearn.model_selection import cross_validate # type: ignore\n",
    "\n",
    "# GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV # type: ignore\n",
    "\n",
    "#Common Model Algorithms\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process # type: ignore\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder # type: ignore\n",
    "from sklearn import feature_selection # type: ignore\n",
    "from sklearn import model_selection # type: ignore\n",
    "from sklearn import metrics # type: ignore\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import matplotlib.pylab as pylab # type: ignore\n",
    "import seaborn as sns # type: ignore\n",
    "from pandas.plotting import scatter_matrix # type: ignore\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder # type: ignore\n",
    "from sklearn.preprocessing import MinMaxScaler # type: ignore\n",
    "from sklearn.linear_model import LogisticRegression # type: ignore\n",
    "from sklearn.metrics import accuracy_score # type: ignore\n",
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "\n",
    "from sklearn.impute import SimpleImputer # type: ignore\n",
    "from sklearn.svm import SVC # type: ignore\n",
    "import os # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  1309 non-null   int64  \n",
      " 1   Survived     891 non-null    float64\n",
      " 2   Pclass       1309 non-null   int64  \n",
      " 3   Name         1309 non-null   object \n",
      " 4   Sex          1309 non-null   object \n",
      " 5   Age          1046 non-null   float64\n",
      " 6   SibSp        1309 non-null   int64  \n",
      " 7   Parch        1309 non-null   int64  \n",
      " 8   Ticket       1309 non-null   object \n",
      " 9   Fare         1308 non-null   float64\n",
      " 10  Cabin        295 non-null    object \n",
      " 11  Embarked     1307 non-null   object \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 122.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "data_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "data_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId       0\n",
      "Survived        418\n",
      "Pclass            0\n",
      "Name              0\n",
      "Sex               0\n",
      "Age               0\n",
      "SibSp             0\n",
      "Parch             0\n",
      "Ticket            0\n",
      "Fare              1\n",
      "Cabin          1014\n",
      "Embarked          2\n",
      "Family_Size       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming data_df is already defined and loaded\n",
    "\n",
    "# Extract Title from Name\n",
    "data_df['Title'] = data_df['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n",
    "\n",
    "# Map rare titles to more common ones\n",
    "mapping = {\n",
    "    'Mlle': 'Miss', 'Mme': 'Mrs', 'Ms': 'Miss', 'Dr': 'Dr',\n",
    "    'Major': 'Mr', 'Lady': 'Mrs', 'Sir': 'Mr', 'Col': 'Mr',\n",
    "    'Capt': 'Mr', 'Countess': 'Mrs', 'Jonkheer': 'Mr',\n",
    "    'Dona': 'Mrs', 'Don': 'Mr', 'Rev': 'Rev', 'Master': 'Master',\n",
    "    'Miss': 'Miss', 'Mr': 'Mr', 'Mrs': 'Mrs'\n",
    "}\n",
    "data_df['Title'] = data_df['Title'].map(mapping)\n",
    "\n",
    "# Fill missing Age based on Title median\n",
    "age_by_title = data_df.groupby('Title')['Age'].median()\n",
    "data_df['Age'] = data_df.apply(lambda row: age_by_title[row['Title']] if pd.isnull(row['Age']) else row['Age'], axis=1)\n",
    "\n",
    "# Create copies of the slices to avoid SettingWithCopyWarning\n",
    "train_df = data_df.loc[:890].copy()\n",
    "test_df = data_df.loc[891:].copy()\n",
    "\n",
    "# Calculate Family_Size and re-split data_df using .loc to avoid SettingWithCopyWarning\n",
    "data_df['Family_Size'] = data_df['Parch'] + data_df['SibSp']\n",
    "train_df['Family_Size'] = train_df['Parch'] + train_df['SibSp']\n",
    "test_df['Family_Size'] = test_df['Parch'] + test_df['SibSp']\n",
    "\n",
    "data_df.drop('Title', axis=1, inplace=True)\n",
    "train_df.drop('Title', axis=1, inplace=True)\n",
    "test_df.drop('Title', axis=1, inplace=True)\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "missing_values = data_df.isnull().sum()\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of passengers with family survival information: 420\n"
     ]
    }
   ],
   "source": [
    "data_df['Last_Name'] = data_df['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "data_df['Fare'] = data_df['Fare'].fillna(data_df['Fare'].median())\n",
    "\n",
    "DEFAULT_SURVIVAL_VALUE = 0.25\n",
    "data_df['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n",
    "\n",
    "for grp, grp_df in data_df[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n",
    "                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n",
    "    \n",
    "    if (len(grp_df) != 1):\n",
    "        # A Family group is found.\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            smax = grp_df.drop(ind)['Survived'].max()\n",
    "            smin = grp_df.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            if (smax == 1):\n",
    "                data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "            elif (smin==0):\n",
    "                data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "\n",
    "tolerance = 1e-10\n",
    "filtered_data_df = data_df[abs(data_df['Family_Survival'] - 0.25) > tolerance]\n",
    "print(\"Number of passengers with family survival information:\", filtered_data_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of passengers with family/group survival information: 546\n"
     ]
    }
   ],
   "source": [
    "for _, grp_df in data_df.groupby('Ticket'):\n",
    "    if (len(grp_df) != 1):\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            if (row['Family_Survival'] == 0) | (np.isclose(row['Family_Survival'], 0.25, rtol=1e-09, atol=1e-09)):\n",
    "                smax = grp_df.drop(ind)['Survived'].max()\n",
    "                smin = grp_df.drop(ind)['Survived'].min()\n",
    "                passID = row['PassengerId']\n",
    "                if (smax == 1):\n",
    "                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "                elif (smin==0):\n",
    "                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "                        \n",
    "# Correcting the line to avoid the ValueError\n",
    "print(\"Number of passengers with family/group survival information:\", \n",
    "      data_df.loc[~np.isclose(data_df['Family_Survival'], 0.25, rtol=1e-09, atol=1e-09)].shape[0])\n",
    "\n",
    "# Assuming data_df is the combined DataFrame of TRAIN_DF and TEST_DF before the split\n",
    "\n",
    "# When initially splitting data_df into train_df and test_df, use .copy()\n",
    "train_df = data_df.iloc[:891].copy()\n",
    "test_df = data_df.iloc[891:].copy()\n",
    "\n",
    "# After ensuring train_df and test_df are copies, you can then safely use .loc to modify these DataFrames\n",
    "train_indices = train_df.index\n",
    "test_indices = test_df.index\n",
    "\n",
    "train_df.loc[train_indices, 'Family_Survival'] = data_df.loc[train_indices, 'Family_Survival']\n",
    "test_df.loc[test_indices, 'Family_Survival'] = data_df.loc[test_indices, 'Family_Survival']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1       0.0       3   \n",
      "1            2       1.0       1   \n",
      "2            3       1.0       3   \n",
      "3            4       1.0       1   \n",
      "4            5       0.0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket Cabin Embarked  Family_Size  Last_Name  \\\n",
      "0      0         A/5 21171   NaN        S            1     Braund   \n",
      "1      0          PC 17599   C85        C            1    Cumings   \n",
      "2      0  STON/O2. 3101282   NaN        S            0  Heikkinen   \n",
      "3      0            113803  C123        S            1   Futrelle   \n",
      "4      0            373450   NaN        S            0      Allen   \n",
      "\n",
      "   Family_Survival  FareBin_Code  \n",
      "0             0.25             0  \n",
      "1             0.25             4  \n",
      "2             0.25             1  \n",
      "3             0.00             4  \n",
      "4             0.25             1  \n"
     ]
    }
   ],
   "source": [
    "# Use the assignment directly instead of inplace=True\n",
    "data_df['Fare'] = data_df['Fare'].fillna(data_df['Fare'].median())\n",
    "\n",
    "# Making Bins\n",
    "data_df['FareBin'] = pd.qcut(data_df['Fare'], 5)\n",
    "\n",
    "label = LabelEncoder()\n",
    "data_df['FareBin_Code'] = label.fit_transform(data_df['FareBin'])\n",
    "\n",
    "# Create copies of the slices to avoid SettingWithCopyWarning\n",
    "train_df = data_df.loc[:890].copy()\n",
    "test_df = data_df.loc[891:].copy()\n",
    "\n",
    "# Assign the 'FareBin_Code' values back to train_df and test_df\n",
    "train_df['FareBin_Code'] = train_df['FareBin_Code']\n",
    "test_df['FareBin_Code'] = test_df['FareBin_Code']\n",
    "\n",
    "# Drop the original 'Fare' column as it's now represented by 'FareBin_Code'\n",
    "train_df.drop(columns=['Fare'], inplace=True)\n",
    "test_df.drop(columns=['Fare'], inplace=True)\n",
    "# Drop the 'FareBin' column as it's now represented by 'FareBin_Code'\n",
    "train_df.drop(columns=['FareBin'], inplace=True)\n",
    "test_df.drop(columns=['FareBin'], inplace=True)\n",
    "\n",
    "# Display the first few rows of the updated training DataFrame to verify the changes\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['AgeBin'] = pd.qcut(data_df['Age'], 4)\n",
    "\n",
    "label = LabelEncoder()\n",
    "data_df['AgeBin_Code'] = label.fit_transform(data_df['AgeBin'])\n",
    "\n",
    "train_df['AgeBin_Code'] = data_df['AgeBin_Code'][:891]\n",
    "test_df['AgeBin_Code'] = data_df['AgeBin_Code'][891:]\n",
    "\n",
    "train_df.drop(columns=['Age'], inplace=True)\n",
    "test_df.drop(columns=['Age'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>Family_Survival</th>\n",
       "      <th>FareBin_Code</th>\n",
       "      <th>AgeBin_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>Kelly</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Wilkes</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>Myles</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Wirz</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>Hirvonen</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "891          892       NaN       3   \n",
       "892          893       NaN       3   \n",
       "893          894       NaN       2   \n",
       "894          895       NaN       3   \n",
       "895          896       NaN       3   \n",
       "\n",
       "                                             Name     Sex  SibSp  Parch  \\\n",
       "891                              Kelly, Mr. James    male      0      0   \n",
       "892              Wilkes, Mrs. James (Ellen Needs)  female      1      0   \n",
       "893                     Myles, Mr. Thomas Francis    male      0      0   \n",
       "894                              Wirz, Mr. Albert    male      0      0   \n",
       "895  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female      1      1   \n",
       "\n",
       "      Ticket Cabin Embarked  Family_Size Last_Name  Family_Survival  \\\n",
       "891   330911   NaN        Q            0     Kelly             0.25   \n",
       "892   363272   NaN        S            1    Wilkes             0.25   \n",
       "893   240276   NaN        Q            0     Myles             0.25   \n",
       "894   315154   NaN        S            0      Wirz             0.25   \n",
       "895  3101298   NaN        S            2  Hirvonen             1.00   \n",
       "\n",
       "     FareBin_Code  AgeBin_Code  \n",
       "891             0            2  \n",
       "892             0            3  \n",
       "893             1            3  \n",
       "894             1            1  \n",
       "895             2            0  "
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  Sex  Family_Size  Family_Survival  \\\n",
      "0            1       0.0       3    0            1             0.25   \n",
      "1            2       1.0       1    1            1             0.25   \n",
      "2            3       1.0       3    1            0             0.25   \n",
      "\n",
      "   FareBin_Code  AgeBin_Code  \n",
      "0             0            0  \n",
      "1             4            3  \n",
      "2             1            1  \n",
      "     PassengerId  Survived  Pclass  Sex  Family_Size  Family_Survival  \\\n",
      "891          892       NaN       3    0            0             0.25   \n",
      "892          893       NaN       3    1            1             0.25   \n",
      "893          894       NaN       2    0            0             0.25   \n",
      "\n",
      "     FareBin_Code  AgeBin_Code  \n",
      "891             0            2  \n",
      "892             0            3  \n",
      "893             1            3  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/6tmkkgpj27z6jk5lyd9m73_00000gn/T/ipykernel_9743/1223678202.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df['Sex'] = train_df['Sex'].replace(['male', 'female'], [0, 1]).astype(int)\n",
      "/var/folders/82/6tmkkgpj27z6jk5lyd9m73_00000gn/T/ipykernel_9743/1223678202.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_df['Sex'] = test_df['Sex'].replace(['male', 'female'], [0, 1]).astype(int)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming train_df, test_df, and data_df have been previously defined\n",
    "\n",
    "# Replace 'male' and 'female' with 1 and 0, respectively\n",
    "# Use the replace method and explicitly handle the downcasting behavior\n",
    "train_df['Sex'] = train_df['Sex'].replace(['male', 'female'], [0, 1]).astype(int)\n",
    "\n",
    "test_df['Sex'] = test_df['Sex'].replace(['male', 'female'], [0, 1]).astype(int)\n",
    "\n",
    "train_df.dropna(subset=['Sex'], inplace=True)\n",
    "test_df.dropna(subset=['Sex'], inplace=True)\n",
    "\n",
    "# Drop unnecessary columns from both datasets\n",
    "columns_to_drop = ['Name', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Embarked', 'Last_Name']\n",
    "train_df.drop(columns=columns_to_drop, inplace=True)\n",
    "test_df.drop(columns=columns_to_drop, inplace=True)\n",
    "data_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Display the first few rows of the training dataframe\n",
    "print(train_df.head(3))\n",
    "print(test_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (891, 7) y.shape (891,) X_test.shape (418, 7)\n"
     ]
    }
   ],
   "source": [
    "# drop survived from X\n",
    "X = train_df.drop('Survived', axis=1)\n",
    "# y has to have only 'PassengerId', 'Survived' columns\n",
    "y = train_df['Survived'].astype(int)\n",
    "X_test = test_df.copy().drop('Survived', axis=1)\n",
    "print(\"X.shape\", X.shape,\"y.shape\", y.shape, \"X_test.shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X    PassengerId  Pclass  Sex  Family_Size  Family_Survival  FareBin_Code  \\\n",
      "0            1       3    0            1             0.25             0   \n",
      "1            2       1    1            1             0.25             4   \n",
      "2            3       3    1            0             0.25             1   \n",
      "3            4       1    1            1             0.00             4   \n",
      "4            5       3    0            0             0.25             1   \n",
      "\n",
      "   AgeBin_Code  \n",
      "0            0  \n",
      "1            3  \n",
      "2            1  \n",
      "3            2  \n",
      "4            2  \n",
      "X_test      PassengerId  Pclass  Sex  Family_Size  Family_Survival  FareBin_Code  \\\n",
      "891          892       3    0            0             0.25             0   \n",
      "892          893       3    1            1             0.25             0   \n",
      "893          894       2    0            0             0.25             1   \n",
      "894          895       3    0            0             0.25             1   \n",
      "895          896       3    1            2             1.00             2   \n",
      "\n",
      "     AgeBin_Code  \n",
      "891            2  \n",
      "892            3  \n",
      "893            3  \n",
      "894            1  \n",
      "895            0  \n"
     ]
    }
   ],
   "source": [
    "print(\"X\", X.head())\n",
    "print(\"X_test\", X_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Defining models for the voting classifier\n",
    "knn_models = [\n",
    "    ('knn1', KNeighborsClassifier(n_neighbors=4, leaf_size=1, weights='uniform')),\n",
    "    ('knn2', KNeighborsClassifier(algorithm='auto', leaf_size=26, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=18, p=2,\n",
    "           weights='uniform')),\n",
    "    ('knn3', KNeighborsClassifier(algorithm='auto', leaf_size=26, metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=18, p=2, weights='uniform')),\n",
    "]\n",
    "random_forest = ('rf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "svc = ('svc', SVC(probability=True, kernel='linear'))\n",
    "\n",
    "# Combining all models into a voting classifier\n",
    "models = knn_models + [random_forest, svc]\n",
    "voting_clf = VotingClassifier(estimators=models, voting='soft')\n",
    "\n",
    "# Fit the voting classifier on scaled data\n",
    "voting_clf.fit(X_scaled, y)\n",
    "\n",
    "# Predict using the ensemble of models\n",
    "y_pred = voting_clf.predict(X_test_scaled)\n",
    "\n",
    "# Prepare the submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': y_pred\n",
    "})\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = '../data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv(f'{output_dir}/gender_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 240 candidates, totalling 2400 fits\n",
      "0.4429411764705883\n",
      "KNeighborsClassifier(leaf_size=11, n_neighbors=7)\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = [6,7,8,9,10,11,12,14,16,18,20,22]\n",
    "algorithm = ['auto']\n",
    "weights = ['uniform', 'distance']\n",
    "leaf_size = list(range(1,50,5))\n",
    "hyperparams = {'algorithm': algorithm, 'weights': weights, 'leaf_size': leaf_size, \n",
    "               'n_neighbors': n_neighbors}\n",
    "gd=GridSearchCV(estimator = KNeighborsClassifier(), param_grid = hyperparams, verbose=True, \n",
    "                cv=10, scoring = \"roc_auc\")\n",
    "gd.fit(X, y)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
